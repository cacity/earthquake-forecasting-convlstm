#!/usr/bin/env python
"""
å®Œæ•´çš„è®­ç»ƒæµç¨‹è„šæœ¬
ç”¨é€”ï¼šä»é›¶å¼€å§‹ï¼Œä¸‹è½½æ•°æ®ã€å¤„ç†æ•°æ®ã€è®­ç»ƒæ¨¡å‹
"""

import subprocess
import sys
from pathlib import Path
import os

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å®æ—¶è¾“å‡º"""
    print(f"\n{'='*80}")
    if description:
        print(f"â–¶ {description}")
    print(f"{'='*80}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print()

    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )

        for line in process.stdout:
            print(line, end='')

        process.wait()

        if process.returncode != 0:
            print(f"\nâŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
            return False
        else:
            print(f"\nâœ… å®Œæˆ")
            return True

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return False

def check_file(path, description=""):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    p = Path(path)
    exists = p.exists()
    size_str = ""
    if exists and p.is_file():
        size = p.stat().st_size
        if size > 1024*1024*1024:
            size_str = f" ({size/1024/1024/1024:.2f} GB)"
        elif size > 1024*1024:
            size_str = f" ({size/1024/1024:.2f} MB)"
        elif size > 1024:
            size_str = f" ({size/1024:.2f} KB)"
        else:
            size_str = f" ({size} bytes)"

    status = "âœ…" if exists else "âŒ"
    desc_str = f" - {description}" if description else ""
    print(f"  {status} {path}{size_str}{desc_str}")
    return exists

def create_symlinks():
    """åˆ›å»ºç¬¦å·é“¾æ¥ï¼Œè®©è¯„ä¼°è„šæœ¬èƒ½æ‰¾åˆ°æ–‡ä»¶"""
    print(f"\n{'='*80}")
    print("åˆ›å»ºç¬¦å·é“¾æ¥ï¼ˆé€‚é…è¯„ä¼°è„šæœ¬è·¯å¾„ï¼‰")
    print(f"{'='*80}\n")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    Path("data/processed").mkdir(parents=True, exist_ok=True)

    # å®šä¹‰é“¾æ¥æ˜ å°„
    links = [
        ("data/processed/splits_L12_H1/train_Y.npy", "data/processed/train_labels.npy"),
        ("data/processed/splits_L12_H1/val_Y.npy", "data/processed/val_labels.npy"),
        ("data/processed/splits_L12_H1/test_Y.npy", "data/processed/test_labels.npy"),
        ("data/processed/splits_L12_H1/test_X.npy", "data/processed/test_features.npy"),
    ]

    for source, link in links:
        source_path = Path(source)
        link_path = Path(link)

        if source_path.exists():
            # åˆ é™¤å·²å­˜åœ¨çš„é“¾æ¥
            if link_path.exists() or link_path.is_symlink():
                link_path.unlink()

            # åˆ›å»ºç›¸å¯¹è·¯å¾„çš„ç¬¦å·é“¾æ¥
            relative_source = Path("splits_L12_H1") / source_path.name
            link_path.symlink_to(relative_source)
            print(f"  âœ… {link} -> {relative_source}")
        else:
            print(f"  âš ï¸  æºæ–‡ä»¶ä¸å­˜åœ¨: {source}")

def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   IEEE Access è®ºæ–‡ - å®Œæ•´è®­ç»ƒæµç¨‹                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è¿™ä¸ªè„šæœ¬å°†æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:
  1. ä¸‹è½½ USGS åœ°éœ‡æ•°æ® (2000-2025)
  2. æ„å»ºå¼ é‡ (grid-based features)
  3. åˆ›å»ºæ ·æœ¬ (lookback=12, horizon=1)
  4. åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
  5. è®­ç»ƒ ConvLSTM æ¨¡å‹ (50 epochs, early stopping)

é¢„è®¡æ€»æ—¶é—´: 30-60 åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦å’Œç¡¬ä»¶ï¼‰

æ³¨æ„:
  - éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼ˆä¸‹è½½ USGS æ•°æ®ï¼‰
  - å»ºè®®æœ‰ GPUï¼ˆCPU ä¹Ÿå¯ä»¥ï¼Œä½†ä¼šæ…¢ä¸€äº›ï¼‰
    """)

    input("æŒ‰ Enter ç»§ç»­ï¼Œæˆ– Ctrl+C å–æ¶ˆ...")

    # è¿›å…¥é¡¹ç›®ç›®å½•
    project_dir = Path(__file__).parent
    os.chdir(project_dir)

    print(f"\nå·¥ä½œç›®å½•: {project_dir.absolute()}")
    print(f"Python: {sys.executable}")
    print(f"ç‰ˆæœ¬: {sys.version}")

    # è¿è¡Œ pipeline
    success = run_command(
        [sys.executable, "run_pipeline.py", "--config", "configs/pipeline_for_paper.json"],
        description="è¿è¡Œå®Œæ•´ Pipeline"
    )

    if not success:
        print("\nâŒ Pipeline æ‰§è¡Œå¤±è´¥ï¼")
        print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ï¼Œä¿®å¤é—®é¢˜åé‡æ–°è¿è¡Œã€‚")
        return 1

    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    print(f"\n{'='*80}")
    print("æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶")
    print(f"{'='*80}\n")

    print("1. åŸå§‹æ•°æ®:")
    check_file("data/interim/events_southwest.parquet", "USGS åœ°éœ‡äº‹ä»¶")

    print("\n2. å¤„ç†åçš„å¼ é‡:")
    check_file("data/processed/X.npy", "ç‰¹å¾å¼ é‡")
    check_file("data/processed/Y.npy", "æ ‡ç­¾å¼ é‡")
    check_file("data/processed/grid_meta.json", "ç½‘æ ¼å…ƒæ•°æ®")

    print("\n3. è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†:")
    check_file("data/processed/splits_L12_H1/train_X.npy", "è®­ç»ƒç‰¹å¾")
    check_file("data/processed/splits_L12_H1/train_Y.npy", "è®­ç»ƒæ ‡ç­¾")
    check_file("data/processed/splits_L12_H1/val_X.npy", "éªŒè¯ç‰¹å¾")
    check_file("data/processed/splits_L12_H1/val_Y.npy", "éªŒè¯æ ‡ç­¾")
    check_file("data/processed/splits_L12_H1/test_X.npy", "æµ‹è¯•ç‰¹å¾")
    check_file("data/processed/splits_L12_H1/test_Y.npy", "æµ‹è¯•æ ‡ç­¾")

    print("\n4. è®­ç»ƒå¥½çš„æ¨¡å‹:")
    model_exists = check_file("outputs/convlstm/best_model.pth", "æœ€ä½³æ¨¡å‹æƒé‡")
    preds_exists = check_file("outputs/convlstm/test_preds.npy", "æµ‹è¯•é›†é¢„æµ‹")
    test_logits = check_file("outputs/convlstm/test_logits.npy", "æµ‹è¯•é›† logits")
    val_logits = check_file("outputs/convlstm/val_logits.npy", "éªŒè¯é›† logits")

    # åˆ›å»ºç¬¦å·é“¾æ¥
    create_symlinks()

    # æœ€ç»ˆæ£€æŸ¥
    print(f"\n{'='*80}")
    print("æœ€ç»ˆæ£€æŸ¥ - è¯„ä¼°è„šæœ¬æ‰€éœ€æ–‡ä»¶")
    print(f"{'='*80}\n")

    all_ready = True
    required_files = [
        ("outputs/convlstm/test_preds.npy", "æ¨¡å‹é¢„æµ‹"),
        ("outputs/convlstm/test_logits.npy", "æµ‹è¯• logits"),
        ("outputs/convlstm/val_logits.npy", "éªŒè¯ logits"),
        ("data/processed/train_labels.npy", "è®­ç»ƒæ ‡ç­¾"),
        ("data/processed/val_labels.npy", "éªŒè¯æ ‡ç­¾"),
        ("data/processed/test_labels.npy", "æµ‹è¯•æ ‡ç­¾"),
        ("data/processed/test_features.npy", "æµ‹è¯•ç‰¹å¾"),
    ]

    for file_path, desc in required_files:
        exists = check_file(file_path, desc)
        if not exists:
            all_ready = False

    # æ‰“å°ä¸‹ä¸€æ­¥æŒ‡ç¤º
    print(f"\n{'='*80}")
    if all_ready:
        print("ğŸ‰ æ‰€æœ‰å‡†å¤‡å·¥ä½œå®Œæˆï¼")
        print(f"{'='*80}\n")
        print("ä½ ç°åœ¨å¯ä»¥:")
        print("\n1. ç”ŸæˆåŸºçº¿æ¨¡å‹é¢„æµ‹ï¼ˆ5åˆ†é’Ÿï¼‰:")
        print("   python generate_baselines.py")
        print("\n2. è¿è¡Œå®Œæ•´è¯„ä¼°ï¼ˆ30-60åˆ†é’Ÿï¼‰:")
        print("   python scripts/run_comprehensive_evaluation.py \\")
        print("     --model-preds outputs/convlstm/test_preds.npy \\")
        print("     --test-labels data/processed/test_labels.npy \\")
        print("     --model-logits outputs/convlstm/test_logits.npy \\")
        print("     --val-labels data/processed/val_labels.npy \\")
        print("     --val-logits outputs/convlstm/val_logits.npy \\")
        print("     --train-labels data/processed/train_labels.npy \\")
        print("     --test-features data/processed/test_features.npy \\")
        print("     --output-dir paper_evaluation_results \\")
        print("     --n-bootstrap 1000")
        print("\nè¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹: QUICKSTART.md")
    else:
        print("âš ï¸  æœ‰æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")
        print(f"{'='*80}\n")
        return 1

    return 0

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
